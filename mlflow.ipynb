{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow= pd.read_csv('GUIDE_Train.csv',nrows=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flow.columns = df_flow.columns.str.lower()\n",
    "\n",
    "# more then 50% null data columns\n",
    "df_flow = df_flow.drop(columns=['resourcetype',\n",
    " 'actiongrouped',\n",
    " 'actiongranular',\n",
    " 'threatfamily',\n",
    " 'emailclusterid',\n",
    " 'antispamdirection',\n",
    " 'roles',\n",
    " 'suspicionlevel',\n",
    " 'lastverdict',\n",
    " 'mitretechniques'])\n",
    "\n",
    "# dorp null rows overall data set\n",
    "df_flow = df_flow.dropna()\n",
    "\n",
    "# datetime Feature extraction\n",
    "df_flow['timestamp'] = pd.to_datetime(df_flow['timestamp'])\n",
    "\n",
    "df_flow['year'] = df_flow['timestamp'].dt.year\n",
    "df_flow['month'] = df_flow['timestamp'].dt.month\n",
    "df_flow['day'] = df_flow['timestamp'].dt.day\n",
    "df_flow['hour'] = df_flow['timestamp'].dt.hour\n",
    "df_flow['minute'] = df_flow['timestamp'].dt.minute\n",
    "\n",
    "df_flow.drop('timestamp', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the target column to last index\n",
    "clumn = ['id', 'orgid', 'incidentid', 'alertid', 'detectorid', 'alerttitle',\n",
    "       'category', 'entitytype', 'evidencerole', 'deviceid',\n",
    "       'ipaddress', 'url', 'accountsid', 'accountupn', 'devicename',\n",
    "       'networkmessageid', 'registrykey', 'registryvaluename',\n",
    "       'registryvaluedata', 'applicationid', 'oauthapplicationid', 'filename',\n",
    "       'resourceidname', 'osfamily', 'state', 'year', 'month', 'day', 'hour',\n",
    "       'minute', 'incidentgrade']\n",
    "\n",
    "df_flow = df_flow[clumn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 99475 entries, 0 to 99999\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  99475 non-null  int64 \n",
      " 1   orgid               99475 non-null  int64 \n",
      " 2   incidentid          99475 non-null  int64 \n",
      " 3   alertid             99475 non-null  int64 \n",
      " 4   detectorid          99475 non-null  int64 \n",
      " 5   alerttitle          99475 non-null  int64 \n",
      " 6   category            99475 non-null  object\n",
      " 7   entitytype          99475 non-null  object\n",
      " 8   evidencerole        99475 non-null  object\n",
      " 9   deviceid            99475 non-null  int64 \n",
      " 10  ipaddress           99475 non-null  int64 \n",
      " 11  url                 99475 non-null  int64 \n",
      " 12  accountsid          99475 non-null  int64 \n",
      " 13  accountupn          99475 non-null  int64 \n",
      " 14  devicename          99475 non-null  int64 \n",
      " 15  networkmessageid    99475 non-null  int64 \n",
      " 16  registrykey         99475 non-null  int64 \n",
      " 17  registryvaluename   99475 non-null  int64 \n",
      " 18  registryvaluedata   99475 non-null  int64 \n",
      " 19  applicationid       99475 non-null  int64 \n",
      " 20  oauthapplicationid  99475 non-null  int64 \n",
      " 21  filename            99475 non-null  int64 \n",
      " 22  resourceidname      99475 non-null  int64 \n",
      " 23  osfamily            99475 non-null  int64 \n",
      " 24  state               99475 non-null  int64 \n",
      " 25  year                99475 non-null  int32 \n",
      " 26  month               99475 non-null  int32 \n",
      " 27  day                 99475 non-null  int32 \n",
      " 28  hour                99475 non-null  int32 \n",
      " 29  minute              99475 non-null  int32 \n",
      " 30  incidentgrade       99475 non-null  object\n",
      "dtypes: int32(5), int64(22), object(4)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df_flow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incidentgrade\n",
       "BenignPositive    43024\n",
       "TruePositive      34887\n",
       "FalsePositive     21564\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_flow['incidentgrade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incidentgrade\n",
      "BenignPositive    21564\n",
      "TruePositive      21564\n",
      "FalsePositive     21564\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming your dataframe is called 'df' and the column is 'incidentgrade'\n",
    "\n",
    "# Get the value counts\n",
    "value_counts = df_flow['incidentgrade'].value_counts()\n",
    "\n",
    "# Find the minimum count\n",
    "min_count = value_counts.min()\n",
    "\n",
    "# Create a list to store the balanced dataframes\n",
    "balanced_dfs = []\n",
    "\n",
    "# Undersample each class\n",
    "for class_value in value_counts.index:\n",
    "    class_df = df_flow[df_flow['incidentgrade'] == class_value]\n",
    "\n",
    "    if len(class_df) > min_count:\n",
    "        # Undersample\n",
    "        undersampled_df = resample(class_df,\n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=min_count,\n",
    "                                   random_state=42)  # reproducible results\n",
    "        balanced_dfs.append(undersampled_df)\n",
    "    else:\n",
    "        # If this class is already at or below the minimum, keep all samples\n",
    "        balanced_dfs.append(class_df)\n",
    "\n",
    "# Combine the balanced dataframes\n",
    "df_balanced = pd.concat(balanced_dfs)\n",
    "\n",
    "# Verify the new class distribution\n",
    "print(df_balanced['incidentgrade'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('train_FE_out_cls_blnc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>orgid</th>\n",
       "      <th>incidentid</th>\n",
       "      <th>alertid</th>\n",
       "      <th>detectorid</th>\n",
       "      <th>alerttitle</th>\n",
       "      <th>category</th>\n",
       "      <th>entitytype</th>\n",
       "      <th>evidencerole</th>\n",
       "      <th>deviceid</th>\n",
       "      <th>...</th>\n",
       "      <th>filename</th>\n",
       "      <th>resourceidname</th>\n",
       "      <th>osfamily</th>\n",
       "      <th>state</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>incidentgrade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214748366556</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>1344358</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>CredentialAccess</td>\n",
       "      <td>CloudLogonRequest</td>\n",
       "      <td>Related</td>\n",
       "      <td>98799</td>\n",
       "      <td>...</td>\n",
       "      <td>289573</td>\n",
       "      <td>3586</td>\n",
       "      <td>5</td>\n",
       "      <td>1445</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>352187320015</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>949228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>InitialAccess</td>\n",
       "      <td>CloudLogonSession</td>\n",
       "      <td>Related</td>\n",
       "      <td>98799</td>\n",
       "      <td>...</td>\n",
       "      <td>289573</td>\n",
       "      <td>3586</td>\n",
       "      <td>5</td>\n",
       "      <td>1445</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>884763264312</td>\n",
       "      <td>216</td>\n",
       "      <td>82016</td>\n",
       "      <td>119304</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>InitialAccess</td>\n",
       "      <td>MailCluster</td>\n",
       "      <td>Related</td>\n",
       "      <td>98799</td>\n",
       "      <td>...</td>\n",
       "      <td>289573</td>\n",
       "      <td>3586</td>\n",
       "      <td>5</td>\n",
       "      <td>1445</td>\n",
       "      <td>6</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  orgid  incidentid  alertid  detectorid  alerttitle  \\\n",
       "0  214748366556      0         114  1344358          14          12   \n",
       "1  352187320015      0         122   949228           0           0   \n",
       "2  884763264312    216       82016   119304           6           5   \n",
       "\n",
       "           category         entitytype evidencerole  deviceid  ...  filename  \\\n",
       "0  CredentialAccess  CloudLogonRequest      Related     98799  ...    289573   \n",
       "1     InitialAccess  CloudLogonSession      Related     98799  ...    289573   \n",
       "2     InitialAccess        MailCluster      Related     98799  ...    289573   \n",
       "\n",
       "   resourceidname  osfamily  state  month  year  day  hour  minute  \\\n",
       "0            3586         5   1445      6  2024    6    16      20   \n",
       "1            3586         5   1445      6  2024   14    11      52   \n",
       "2            3586         5   1445      6  2024   11    13       9   \n",
       "\n",
       "   incidentgrade  \n",
       "0              2  \n",
       "1              2  \n",
       "2              2  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = df_final.select_dtypes(include='object').columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_column:\n",
    "    df_final[col] = le.fit_transform(df_final[col])\n",
    "\n",
    "X = df_final.iloc[:,:-1]\n",
    "y = df_final.iloc[:,-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.80      0.63      1462\n",
      "           1       0.58      0.48      0.52      1462\n",
      "           2       0.71      0.46      0.56      1462\n",
      "\n",
      "    accuracy                           0.58      4386\n",
      "   macro avg       0.60      0.58      0.57      4386\n",
      "weighted avg       0.60      0.58      0.57      4386\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters in a dictionary\n",
    "params = {\n",
    "    'random_state': None,\n",
    "    'multi_class': 'auto',\n",
    "    'solver': 'lbfgs',\n",
    "    'max_iter': 100\n",
    "}\n",
    "# Initialize the Logistic Regression model with the defined parameters\n",
    "model = LogisticRegression(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report_dict = classification_report(y_test,y_pred)\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      1462\n",
      "           1       0.92      0.92      0.92      1462\n",
      "           2       1.00      0.94      0.97      1462\n",
      "\n",
      "    accuracy                           0.93      4386\n",
      "   macro avg       0.94      0.93      0.93      4386\n",
      "weighted avg       0.94      0.93      0.93      4386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Define the parameters for Random Forest in a dictionary\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'random_state': None,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'bootstrap': True\n",
    "}\n",
    "rf_model = RandomForestClassifier(**rf_params)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred_rf)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.99      0.67       434\n",
      "           1       0.74      0.13      0.22       206\n",
      "           2       0.97      0.31      0.47       360\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.74      0.48      0.45      1000\n",
      "weighted avg       0.72      0.57      0.50      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_ = rf_model.predict(X_test_)\n",
    "\n",
    "report = classification_report(y_test_, y_pred_)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation Accuracy: 0.93 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Print the average accuracy and standard deviation\n",
    "print(\"Cross-validation Accuracy: %0.2f (+/- %0.2f)\" % (cv_scores.mean(), cv_scores.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.80      0.63      1462\n",
      "           1       0.58      0.48      0.52      1462\n",
      "           2       0.71      0.46      0.56      1462\n",
      "\n",
      "    accuracy                           0.58      4386\n",
      "   macro avg       0.60      0.58      0.57      4386\n",
      "weighted avg       0.60      0.58      0.57      4386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for KNN in a dictionary\n",
    "knn_params = {\n",
    "    'n_neighbors': 2,  # Number of neighbors to use\n",
    "    'weights': 'uniform',  # Weight function used in prediction\n",
    "    'algorithm': 'auto',  # Algorithm used to compute the nearest neighbors\n",
    "    'p': 2  # Power parameter for the Minkowski metric (2 for Euclidean distance)\n",
    "}\n",
    "\n",
    "# Initialize the KNN model with the defined parameters\n",
    "knn_model = KNeighborsClassifier(**knn_params)\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "knn_report = classification_report(y_test,y_pred)\n",
    "print(knn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.80      0.63      1462\n",
      "           1       0.58      0.48      0.52      1462\n",
      "           2       0.71      0.46      0.56      1462\n",
      "\n",
      "    accuracy                           0.58      4386\n",
      "   macro avg       0.60      0.58      0.57      4386\n",
      "weighted avg       0.60      0.58      0.57      4386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting rounds\n",
    "    'max_depth': 3,  # Maximum depth of trees\n",
    "    'learning_rate': 0.1,  # Step size shrinkage\n",
    "    'subsample': 0.8,  # Proportion of samples to use for each tree\n",
    "    'colsample_bytree': 0.8,  # Proportion of features to use for each tree\n",
    "    'objective': 'multi:softmax',  # Multi-class classification objective\n",
    "    'num_class': 3,  # Number of classes\n",
    "    'eval_metric': 'mlogloss'  # Evaluation metric\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_report = classification_report(y_test,y_pred)\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m gb_params \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m,  \u001b[38;5;66;03m# Number of boosting stages to be run\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.1\u001b[39m,  \u001b[38;5;66;03m# Learning rate shrinks the contribution of each tree\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcriterion\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfriedman_mse\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Function to measure the quality of a split (default is 'friedman_mse')\u001b[39;00m\n\u001b[0;32m     11\u001b[0m }\n\u001b[0;32m     13\u001b[0m gb_model \u001b[38;5;241m=\u001b[39m GradientBoostingClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgb_params)\n\u001b[1;32m---> 14\u001b[0m gb_model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     15\u001b[0m y_pred_gb \u001b[38;5;241m=\u001b[39m gb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     17\u001b[0m gb_report \u001b[38;5;241m=\u001b[39m classification_report(y_test,y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameters for Gradient Boosting in a dictionary\n",
    "gb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting stages to be run\n",
    "    'learning_rate': 0.1,  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': 3,  # Maximum depth of the individual trees\n",
    "    'subsample': 1.0,  # Proportion of samples to use for fitting each individual tree\n",
    "    'criterion': 'friedman_mse'  # Function to measure the quality of a split (default is 'friedman_mse')\n",
    "}\n",
    "\n",
    "gb_model = GradientBoostingClassifier(**gb_params)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "gb_report = classification_report(y_test,y_pred)\n",
    "print(gb_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {\n",
    "    'random_state': None,\n",
    "    'multi_class': 'auto',\n",
    "    'solver': 'lbfgs',\n",
    "    'max_iter': 100\n",
    "}\n",
    "rf_params = {\n",
    "    'n_estimators': 100,\n",
    "    'random_state': None,\n",
    "    'max_depth': None,\n",
    "    'min_samples_split': 2,\n",
    "    'min_samples_leaf': 1,\n",
    "    'bootstrap': True\n",
    "}\n",
    "knn_params = {\n",
    "    'n_neighbors': 2,  # Number of neighbors to use\n",
    "    'weights': 'uniform',  # Weight function used in prediction\n",
    "    'algorithm': 'auto',  # Algorithm used to compute the nearest neighbors\n",
    "    'p': 2  # Power parameter for the Minkowski metric (2 for Euclidean distance)\n",
    "}\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting rounds\n",
    "    'max_depth': 3,  # Maximum depth of trees\n",
    "    'learning_rate': 0.1,  # Step size shrinkage\n",
    "    'subsample': 0.8,  # Proportion of samples to use for each tree\n",
    "    'colsample_bytree': 0.8,  # Proportion of features to use for each tree\n",
    "    'objective': 'multi:softmax',  # Multi-class classification objective\n",
    "    'num_class': 3,  # Number of classes\n",
    "    'eval_metric': 'mlogloss'  # Evaluation metric\n",
    "}\n",
    "gb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting stages to be run\n",
    "    'learning_rate': 0.1,  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': 3,  # Maximum depth of the individual trees\n",
    "    'subsample': 1.0,  # Proportion of samples to use for fitting each individual tree\n",
    "    'criterion': 'friedman_mse'  # Function to measure the quality of a split (default is 'friedman_mse')\n",
    "}\n",
    "models = [(\n",
    "    \"Logistic regression\",\n",
    "    LogisticRegression(),\n",
    "    lr_params,\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),(\n",
    "    \"Random Forest\",\n",
    "    RandomForestClassifier(),\n",
    "    rf_params,\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),(\n",
    "    \"KNN\",\n",
    "    KNeighborsClassifier(),\n",
    "    knn_params,\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),(\n",
    "    \"XGBClassifier\",\n",
    "    XGBClassifier(),\n",
    "    xgb_params,\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),(\n",
    "    \"GradientBoostingClassifier\",\n",
    "    GradientBoostingClassifier(),\n",
    "    gb_params,\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "reports = []\n",
    "for model_name,model,params,train_set,test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test,y_pred,output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiple model log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/05 11:54:54 INFO mlflow.tracking.fluent: Experiment with name 'train_final' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/05 11:54:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/05 11:54:59 INFO mlflow.tracking._tracking_service.client: 🏃 View run Logistic regression at: http://127.0.0.1:5000/#/experiments/339399093014260649/runs/1196c8060f574a2182fb08860114f1fd.\n",
      "2024/09/05 11:54:59 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/339399093014260649.\n",
      "2024/09/05 11:55:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/05 11:55:03 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/339399093014260649/runs/1910e560bbb344c5b94845463f288622.\n",
      "2024/09/05 11:55:03 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/339399093014260649.\n",
      "2024/09/05 11:55:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/05 11:55:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run KNN at: http://127.0.0.1:5000/#/experiments/339399093014260649/runs/cc58603d58f84ae2870a2624c9dde214.\n",
      "2024/09/05 11:55:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/339399093014260649.\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [11:55:07] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/09/05 11:55:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/05 11:55:11 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/339399093014260649/runs/a5b246bde2744901a96f1a369522ba94.\n",
      "2024/09/05 11:55:11 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/339399093014260649.\n",
      "2024/09/05 11:55:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/05 11:55:15 INFO mlflow.tracking._tracking_service.client: 🏃 View run GradientBoostingClassifier at: http://127.0.0.1:5000/#/experiments/339399093014260649/runs/b00e5721582e449094b00cabdf6081a7.\n",
      "2024/09/05 11:55:15 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/339399093014260649.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"train_final\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "for i ,element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "    {}\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model_name\",model_name)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\",report[\"accuracy\"])\n",
    "        mlflow.log_metric(\"recall_class_0\",report['0']['recall'])\n",
    "        mlflow.log_metric(\"recall_class_1\",report['1']['recall'])\n",
    "        mlflow.log_metric(\"recall_class_2\",report['2']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])\n",
    "\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, model_name)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, model_name)    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# single model log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/02 17:04:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/02 17:04:02 INFO mlflow.tracking._tracking_service.client: 🏃 View run rare-kit-813 at: http://127.0.0.1:5000/#/experiments/344090298825934818/runs/9ace973b3e7e4bef870370bbced208e2.\n",
      "2024/09/02 17:04:02 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/344090298825934818.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"first Expriment\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metrics({\n",
    "        \"accuracy\" : report_dict['accuracy'],\n",
    "        \"recall_class_0\" : report_dict['0']['recall'],\n",
    "        \"recall_class_1\" : report_dict['1']['recall'],\n",
    "        \"recall_class_2\" : report_dict['2']['recall'],\n",
    "        \"f1_score_macro\" : report_dict['macro avg']['f1-score']\n",
    "        \n",
    "    })\n",
    "    mlflow.sklearn.log_model(rf_model,\"Random forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model from grid search\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_best_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Generate classification report\n",
    "best_rf_report = classification_report(y_test, y_pred_best_rf)\n",
    "\n",
    "print(\"Best Parameters from Grid Search:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\\nClassification Report of Best Model:\")\n",
    "print(best_rf_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN k-value finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split the data (if not already split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the range of k values to test\n",
    "k_values = range(1, 31)\n",
    "\n",
    "# Store the mean error for each k value\n",
    "mean_errors = []\n",
    "\n",
    "for k in k_values:\n",
    "    # Initialize the KNN model with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on the validation data\n",
    "    y_pred = knn.predict(X_val)\n",
    "    \n",
    "    # Calculate the mean squared error\n",
    "    error = mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    # Store the error\n",
    "    mean_errors.append(error)\n",
    "\n",
    "# Find the k value with the minimum error\n",
    "best_k = k_values[np.argmin(mean_errors)]\n",
    "print(f\"Best k value: {best_k}\")\n",
    "\n",
    "# Plotting the error vs. k values\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, mean_errors, marker='o')\n",
    "plt.xlabel('Number of Neighbors (k)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Error vs. k Value')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
